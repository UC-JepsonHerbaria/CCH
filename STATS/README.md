# CCH STATS

##Timeline: To be completed once every 1-2 months

### Files
`CCH_stats.pl`
`CCH_query_log`

The Consortium of California Herbaria serves as a gateway to information from California vascular plant specimens that are housed in participant herbaria. Records from the California Floristic Province portion of Baja California, Mexico are also included. 

Originally developed in 2003 around botanical collections from University of California herbaria, the Consortium continues to grow as more collections are added.

### Instructions for Updating the CCH Stats perl script and maintaining the CCH query log file

CCH queries are accumulated in a `usr/local/web/ucjeps_data/ucjeps_data/cch_query_log file`.  The contents of this log file get reported at the top of the page at: `ucjeps.berkeley.edu/cgi-bin/cch_stats.pl`.  The log file needs to be appended and emptied periodically because it can get overloaded.  To save the data, the table generated by the current log is saved before truncating the log.

- This should be done once a month, otherwise the script times out and crashes.

- If the CCH Stats page needs to be appended and it has not crashed, complete the procedure in Part I  

- If it has crashed and the log file has been overloaded, follow the split log file script in Part II. 

### Part I. Monthly Log File Processing

1. Process the current log file by accessing the webpage at:

`ucjeps.berkeley.edu/cgi-bin/cch_stats.pl`

2.  The html text produced by the script is not automatically saved into the original file and needs to be appended.  Save the html source into a working directory.


3.  Open the webpage and view the source in a text edit such as Adobe Brackets. 

4.  Log into the Annie server using ftp (fireFTP in Mozilla).

5.  Use FTP to transfer a working copy of the cch_stats.pl file in the  usr/local/web/ucjeps_cgi directory to the working directory on the bioinformatics computer.

6.  View the source of the HTML output of the CCH Stats script.  Copy the html table generated by the current process from the header line (around line 84):
`<table border=1 cellpadding=5><tr><td align="center">`

- To the footer line:
	`</table>Total: XXXXXX</td></tr></table>`    
- [where XXXXXX is the number of searches]

7.  Paste it directly after the `_ _END_ _`  statement (around line 155), but before the header of the previous downloadâ€™s table html.

8.  Truncate and empty the query log file with the command:
`cat /dev/null >| cch_query_log`

	Note: `/dev/null` is a zero-length file with which you are overwriting the log and preserving its permissions.  The resultant empty `cch_query_log` file is in the `usr/local/web/ucjeps_data/ucjeps_data/` directory.

9.  Run a CCH query to test if the script is completing.  View the  CCH stats page to test if the script is correctly appending query results:
`ucjeps.berkeley.edu/cgi-bin/cch_stats.pl`


### Part II.  Splitting and appending a crashed log file.

1.  Log into a ssh session on Annie through Bash. 

- Format:  `username@ annie.bnhm.berkeley.edu`

- Bash Output:

`airbears2-10-142-84-81:~ jalexander

`$ ssh dbaxter@annie.bnhm.berkeley.edu
`dbaxter@annie.bnhm.berkeley.edu's password: XXXXXXXXXX


2.  Annie will output a header file through Bash:

`Last login: Mon Aug 22 10:08:34 2016 from d173-238-206-56.home4.cgocable.net`
`------------------------------------------------------------------------`
`                Welcome to the BNHM Virtual Web Server`

`Home directory path:           /home -> /data/home`
`Data directory path:           /data`
`Web configuration paths:       /etc/httpd/conf`
`                               /etc/httpd/conf.d`
`Custom software path:          /usr/local -> /data/local`
`------------------------------------------------------------------------
`[dbaxter@annie ~]$`


2.  Change to the ucjeps_data directory.

- Bash Output:

`[dbaxter@annie ~]$ cd /usr/local/web/ucjeps_data/ucjeps_data`


3. Split the log file into several parts using the split command. `-l` is a letter l not a number 1.  In Bash, use the command `split --help` for more details.

- Bash Output:

`[dbaxter@annie ucjeps_data]$ split -l 20000000 cch_query_log`


4. The split command will divide the log file into sections of 20 million lines.  The script can only handle files in 20 million line sections.

5.  For every section of 20 million lines, a xaa file will be created in the ucjeps_data directory.  There may be more than one.  In this case, additional files (xab, xac, xad, etc) will be created.

6.  Every file section must now be appended to the log file and an html table created and copied to the cch_stats.pl file in the working directory.

7.  Use the cat command to append the data in the xaa file into the null cch_query_log file.  These two Bash commands accomplish this task.

- Bash Output:

`[dbaxter@annie ucjeps_data]$ cat /dev/null >| cch_query_log`
`[dbaxter@annie ucjeps_data]$ cat xaa >| cch_query_log`


7.  Process the current log file by accessing the webpage at :

`ucjeps.berkeley.edu/cgi-bin/cch_stats.pl`


8.  The html text produced by the script is not automatically saved into the original file and needs to be appended.  Save the html source into a working directory.

9.  Follow steps 6 and 7 of Part I to paste the HTML into the correct lines of the working directory copy of the cch_stats.pl script.

10.  If there are no other section files created skip to step 13.  If there are more than one section files, go to step 11.

11.  Use the cat command to append the data in the xab file into the null cch_query_log file.  These two Bash commands accomplish this task.

Bash Output:

`[dbaxter@annie ucjeps_data]$ cat /dev/null >| cch_query_log`
`[dbaxter@annie ucjeps_data]$ cat xab >| cch_query_log`


12.  Follow steps 7-11 for every section file created by the split command.  Note:  In the above example, just replace the last letter with the letter in the last position of the filename.

- Bash Output:

`[dbaxter@annie ucjeps_data]$ cat /dev/null >| cch_query_log`
`[dbaxter@annie ucjeps_data]$ cat xac >| cch_query_log`

(process html log file steps next)

`[dbaxter@annie ucjeps_data]$ cat /dev/null >| cch_query_log`
`[dbaxter@annie ucjeps_data]$ cat xad >| cch_query_log`


13.  When all file sections have been copied as HTML tables in the `cch_stats.pl` script, use the FTP software to transfer the file back to the `ucjeps.berkeley.edu/cgi-bin/` directory.

14.  Run a CCH query to test if the script is completeing the code.  View the  CCH stats page to test if the log file is correctly appending query results

